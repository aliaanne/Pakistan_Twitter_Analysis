{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import multiprocessing \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FINAL_KP_TWEETS_WITH_TOPICS_SENTIMENTS.pickle', \"rb\") as f:\n",
    "    total_tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display max rows/columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only corruption tweets since 2018\n",
    "tweets = total_tweets[total_tweets[\"topic_name\"]==\"public works and corruption\"]\n",
    "tweets = tweets.set_index(\"index\")\n",
    "tweets = tweets[\"2018-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use keyword search to create dataframes of sub-topics in tweets and remove each categorized tweet from main dataframe.\n",
    "#Combine related tweets into sub-topic dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran = tweets[tweets[\"clean_translation\"].str.contains(\"imran\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"imran\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "khan = tweets[tweets[\"clean_translation\"].str.contains(\"khan\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"khan\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik = tweets[tweets[\"clean_translation\"].str.contains(\"ik\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"ik\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran_khan = pd.concat([imran, khan, ik])\n",
    "imran_khan[\"category\"] = \"imran khan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawaz = tweets[tweets[\"clean_translation\"].str.contains(\"nawaz\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"nawaz\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharif = tweets[tweets[\"clean_translation\"].str.contains(\"sharif\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"sharif\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "nawaz_sharif = pd.concat([nawaz, sharif])\n",
    "nawaz_sharif[\"category\"] = \"nawaz sharif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "dam = tweets[tweets[\"clean_translation\"].str.contains(\"dam\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"dam\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "dam = pd.concat([dam])\n",
    "dam[\"category\"] = \"dam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "jahangir = tweets[tweets[\"clean_translation\"].str.contains(\"jahangir\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"jahangir\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "tareen = tweets[tweets[\"clean_translation\"].str.contains(\"tareen\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"jahangir\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "tareen = pd.concat([tareen, jahangir])\n",
    "tareen[\"category\"] = \"tareen jahangir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime = tweets[tweets[\"clean_translation\"].str.contains(\"prime\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"prime\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran_khan = pd.concat([imran_khan, prime])\n",
    "imran_khan[\"category\"] = \"imran khan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_minister = tweets[tweets[\"clean_translation\"].str.contains(\"finance minister\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"finance minister\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_minister = pd.concat([finance_minister])\n",
    "finance_minister[\"category\"] = \"finance minister\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "pti = tweets[tweets[\"clean_translation\"].str.contains(\"pti\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"pti\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran_khan = pd.concat([imran_khan, pti])\n",
    "imran_khan[\"category\"] = \"imran khan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "chief = tweets[tweets[\"clean_translation\"].str.contains(\"chief\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"chief\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "chief_minister = pd.concat([chief])\n",
    "chief_minister[\"category\"] = \"chief minister\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "bani = tweets[tweets[\"clean_translation\"].str.contains(\"bani\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"bani\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran_khan = pd.concat([imran_khan, bani])\n",
    "imran_khan[\"category\"] = \"imran khan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "dar = tweets[tweets[\"clean_translation\"].str.contains(\"dar\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"dar\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_minister = pd.concat([finance_minister, dar])\n",
    "finance_minister[\"category\"] = \"finance minister\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "benazir = tweets[tweets[\"clean_translation\"].str.contains(\"benazir\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"benazir\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "benazir = pd.concat([benazir])\n",
    "benazir[\"category\"] = \"benazir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "murad = tweets[tweets[\"clean_translation\"].str.contains(\"murad\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"murad\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "murad_saeed = pd.concat([murad])\n",
    "murad_saeed[\"category\"] = \"murad saeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "government = tweets[tweets[\"clean_translation\"].str.contains(\"government\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"government\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "government = pd.concat([government])\n",
    "government[\"category\"] = \"government\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro = tweets[tweets[\"clean_translation\"].str.contains(\"metro\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"metro\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro = pd.concat([metro])\n",
    "metro[\"category\"] = \"metro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = tweets[tweets[\"clean_translation\"].str.contains(\"us\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"us\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "united = tweets[tweets[\"clean_translation\"].str.contains(\"united\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"united\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = tweets[tweets[\"clean_translation\"].str.contains(\"trump\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"trump\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "american = tweets[tweets[\"clean_translation\"].str.contains(\"america\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"america\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "aid = tweets[tweets[\"clean_translation\"].str.contains(\"aid\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"aid\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "united_states = pd.concat([us, united, trump, american, aid])\n",
    "united_states[\"category\"] = \"united states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = tweets[tweets[\"clean_translation\"].str.contains(\"rs\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"rs\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "rupee = tweets[tweets[\"clean_translation\"].str.contains(\"rupee\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"rupee\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = tweets[tweets[\"clean_translation\"].str.contains(\"money\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"money\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar = tweets[tweets[\"clean_translation\"].str.contains(\"dollar\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"dollar\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "billion = tweets[tweets[\"clean_translation\"].str.contains(\"billion\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"billion\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "million = tweets[tweets[\"clean_translation\"].str.contains(\"million\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"million\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = pd.concat([government, rs, rupee, money, dollar, billion, million])\n",
    "money[\"category\"] = \"money\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital = tweets[tweets[\"clean_translation\"].str.contains(\"hospital\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"hospital\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.concat([dam, metro, hospital])\n",
    "projects[\"category\"] = \"projects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all categorized tweets and drop duplicates\n",
    "cat_tweets = pd.concat([imran_khan, nawaz_sharif, projects, tareen, chief_minister, finance_minister, benazir, murad, united_states, money])\n",
    "cat_tweets = cat_tweets.reset_index()\n",
    "cat_tweets = cat_tweets.drop_duplicates([\"index\", \"clean_translation\", \"hashtags\", \"user_id\", \"user_location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set uncategorized tweets equal to \"None\" and combine categorized and uncategorized dataframes and save\n",
    "uncat = tweets\n",
    "uncat[\"category\"] = \"None\"\n",
    "tweets = pd.concat([cat_tweets, uncat])\n",
    "\n",
    "with open(\"kp_corruption_tweets_categorized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
