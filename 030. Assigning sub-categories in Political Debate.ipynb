{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import multiprocessing \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FINAL_KP_TWEETS_WITH_TOPICS_SENTIMENTS.pickle', \"rb\") as f:\n",
    "    total_tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display max columns/rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only political debate tweets since 2018\n",
    "tweets = total_tweets[total_tweets[\"topic_name\"]==\"political debate\"]\n",
    "tweets = tweets.set_index(\"index\")\n",
    "tweets = tweets[\"2018-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use keyword search to create dataframes of sub-topics in tweets and remove each categorized tweet from main dataframe.\n",
    "#Combine related tweets into sub-topic dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pti = tweets[tweets[\"clean_translation\"].str.contains(\"pti\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"pti\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "govt = tweets[tweets[\"clean_translation\"].str.contains(\"govt\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"govt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik = tweets[tweets[\"clean_translation\"].str.contains(\"ik\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"ik\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = tweets[tweets[\"clean_translation\"].str.contains(\"pm\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"pm\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "khan = tweets[tweets[\"clean_translation\"].str.contains(\"khan\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"khan\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmln = tweets[tweets[\"clean_translation\"].str.contains(\"pmln\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"pmln\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "women = tweets[tweets[\"clean_translation\"].str.contains(\"wom\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"wom\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "army = tweets[tweets[\"clean_translation\"].str.contains(\"army\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"army\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = tweets[tweets[\"clean_translation\"].str.contains(\"media\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"media\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = tweets[tweets[\"clean_translation\"].str.contains(\"news\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"news\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = tweets[tweets[\"clean_translation\"].str.contains(\"us\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"us\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = tweets[tweets[\"clean_translation\"].str.contains(\"trump\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"trump\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "american = tweets[tweets[\"clean_translation\"].str.contains(\"ameri\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"ameri\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = tweets[tweets[\"clean_translation\"].str.contains(\"right\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"right\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = tweets[tweets[\"clean_translation\"].str.contains(\"fake\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"fake\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = tweets[tweets[\"clean_translation\"].str.contains(\"vote\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"vote\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalism = tweets[tweets[\"clean_translation\"].str.contains(\"journal\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"journal\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "government = tweets[tweets[\"clean_translation\"].str.contains(\"government\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"government\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = tweets[tweets[\"clean_translation\"].str.contains(\"money\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"money\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "india = tweets[tweets[\"clean_translation\"].str.contains(\"india\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"india\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "election = tweets[tweets[\"clean_translation\"].str.contains(\"election\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"election\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor = tweets[tweets[\"clean_translation\"].str.contains(\"poor\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"poor\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptm = tweets[tweets[\"clean_translation\"].str.contains(\"ptm\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"ptm\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt = tweets[tweets[\"clean_translation\"].str.contains(\"corrupt\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"corrupt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = tweets[tweets[\"clean_translation\"].str.contains(\"state\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"state\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "police = tweets[tweets[\"clean_translation\"].str.contains(\"police\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"police\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp = tweets[tweets[\"clean_translation\"].str.contains(\"ppp\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"ppp\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakistan = tweets[tweets[\"clean_translation\"].str.contains(\"pak\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"pak\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = tweets[tweets[\"clean_translation\"].str.contains(\"party\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"party\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics = tweets[tweets[\"clean_translation\"].str.contains(\"polit\", na=False)]\n",
    "tweets = tweets[~tweets[\"clean_translation\"].str.contains(\"polit\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_government = pd.concat([pti, govt, ik, pm, khan, government, state])\n",
    "current_government[\"category\"] = \"current_government\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmln = pd.concat([pmln])\n",
    "pmln[\"category\"] = \"pmln\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "women = pd.concat([women])\n",
    "women[\"category\"] = \"women\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_forces = pd.concat([army, police])\n",
    "security_forces[\"category\"] = \"security forces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = pd.concat([media, news, fake, journalism])\n",
    "media[\"category\"] = \"media\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "united_states = pd.concat([us, trump, american])\n",
    "united_states[\"category\"] = \"united states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_rights = pd.concat([right])\n",
    "human_rights[\"category\"] = \"human rights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections = pd.concat([vote, election])\n",
    "elections[\"category\"] = \"elections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptm = pd.concat([ptm])\n",
    "ptm[\"category\"] = \"ptm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakistan_politics = pd.concat([pakistan, politics])\n",
    "pakistan_politics[\"category\"] = \"pakistan politics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all categorized tweets and drop duplicates\n",
    "cat_tweets = pd.concat([current_government, pmln, women, security_forces, media, united_states, human_rights, elections, ptm, pakistan_politics])\n",
    "cat_tweets = cat_tweets.reset_index()\n",
    "cat_tweets = cat_tweets.drop_duplicates([\"index\", \"clean_translation\", \"hashtags\", \"user_id\", \"user_location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set uncategorized tweets equal to \"None\" and combine categorized and uncategorized dataframes and save\n",
    "uncat = tweets\n",
    "uncat[\"category\"] = \"None\"\n",
    "tweets = pd.concat([cat_tweets, uncat])\n",
    "with open(\"kp_political_debate_tweets_categorized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
