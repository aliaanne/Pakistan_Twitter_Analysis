{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import multiprocessing \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FINAL_KP_TWEETS_WITH_TOPICS_SENTIMENTS.pickle', \"rb\") as f:\n",
    "    total_tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to view max rows and columns for keyword searches\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View only municipal issues tweets since 2018\n",
    "tweets = total_tweets[total_tweets[\"topic_name\"]==\"municipal issues\"]\n",
    "tweets = tweets.set_index(\"index\")\n",
    "tweets = tweets[\"2018-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for keywords in the data and create dataframes with tweets form each keyword.  Concatenate keywords into larger sub-categories and drop duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = tweets[tweets[\"clean_translation\"].str.contains(\"job\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = tweets[tweets[\"clean_translation\"].str.contains(\"work\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply = tweets[tweets[\"clean_translation\"].str.contains(\"apply\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = tweets[tweets[\"clean_translation\"].str.contains(\"position\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.concat([jobs, work, apply, position])\n",
    "jobs[\"category\"] = \"jobs\"\n",
    "tweets = tweets.drop(jobs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = tweets[tweets[\"clean_translation\"].str.contains(\"edu\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = tweets[tweets[\"clean_translation\"].str.contains(\"school\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = tweets[tweets[\"clean_translation\"].str.contains(\"student\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "university = tweets[tweets[\"clean_translation\"].str.contains(\"univers\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "youth = tweets[tweets[\"clean_translation\"].str.contains(\"youth\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "young = tweets[tweets[\"clean_translation\"].str.contains(\"young\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "teach = tweets[tweets[\"clean_translation\"].str.contains(\"teach\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "college = tweets[tweets[\"clean_translation\"].str.contains(\"college\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = tweets[tweets[\"clean_translation\"].str.contains(\"course\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.concat([edu, school, student, university, youth, young, teach, college, course])\n",
    "education[\"category\"] = \"education\"\n",
    "tweets = tweets.drop(education.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "security = tweets[tweets[\"clean_translation\"].str.contains(\"security\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "police = tweets[tweets[\"clean_translation\"].str.contains(\"police\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "law = tweets[tweets[\"clean_translation\"].str.contains(\"law\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "court = tweets[tweets[\"clean_translation\"].str.contains(\"court\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "security = pd.concat([security, police, law, court])\n",
    "security[\"category\"] = \"security\"\n",
    "tweets = tweets.drop(security.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "development = tweets[tweets[\"clean_translation\"].str.contains(\"develop\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor = tweets[tweets[\"clean_translation\"].str.contains(\"poor\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty = tweets[tweets[\"clean_translation\"].str.contains(\"poverty\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = tweets[tweets[\"clean_translation\"].str.contains(\"project\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "construction = tweets[tweets[\"clean_translation\"].str.contains(\"construc\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "development = pd.concat([development, poor, poverty, project, construction])\n",
    "development[\"category\"] = \"development\"\n",
    "tweets = tweets.drop(development.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = tweets[tweets[\"clean_translation\"].str.contains(\"environ\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tweets[tweets[\"clean_translation\"].str.contains(\"tree\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = tweets[tweets[\"clean_translation\"].str.contains(\"climate\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = tweets[tweets[\"clean_translation\"].str.contains(\"green\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "plastic = tweets[tweets[\"clean_translation\"].str.contains(\"plastic\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = pd.concat([environment, tree, climate, green, plastic])\n",
    "environment[\"category\"] = \"environment\"\n",
    "tweets = tweets.drop(environment.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = tweets[tweets[\"clean_translation\"].str.contains(\"transport\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "street = tweets[tweets[\"clean_translation\"].str.contains(\"street\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "road = tweets[tweets[\"clean_translation\"].str.contains(\"road\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "brt = tweets[tweets[\"clean_translation\"].str.contains(\"brt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorway = tweets[tweets[\"clean_translation\"].str.contains(\"motorway\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = tweets[tweets[\"clean_translation\"].str.contains(\"traffic\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro = tweets[tweets[\"clean_translation\"].str.contains(\"metro\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportation = pd.concat([transport, street, road, brt, motorway, traffic, metro])\n",
    "transportation[\"category\"] = \"transportation\"\n",
    "tweets = tweets.drop(transportation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "citizens_portal = tweets[tweets[\"clean_translation\"].str.contains(\"portal\", na=False)]\n",
    "citizens_portal[\"category\"] = \"citizens portal\"\n",
    "tweets = tweets.drop(citizens_portal.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = tweets[tweets[\"clean_translation\"].str.contains(\"merg\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe = tweets[tweets[\"clean_translation\"].str.contains(\"tribe\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "tribal = tweets[tweets[\"clean_translation\"].str.contains(\"tribal\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "fata = tweets[tweets[\"clean_translation\"].str.contains(\"fata\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = pd.concat([merger, tribe, tribal, fata])\n",
    "merger[\"category\"] = \"merger\"\n",
    "tweets = tweets.drop(merger.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology = tweets[tweets[\"clean_translation\"].str.contains(\"tech\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "science = tweets[tweets[\"clean_translation\"].str.contains(\"science\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital = tweets[tweets[\"clean_translation\"].str.contains(\"digital\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology = pd.concat([technology, science, digital])\n",
    "technology[\"category\"] = \"technology\"\n",
    "tweets = tweets.drop(technology.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "health = tweets[tweets[\"clean_translation\"].str.contains(\"health\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor = tweets[tweets[\"clean_translation\"].str.contains(\"doctor\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital = tweets[tweets[\"clean_translation\"].str.contains(\"hospital\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = tweets[tweets[\"clean_translation\"].str.contains(\"insurance\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona = tweets[tweets[\"clean_translation\"].str.contains(\"corona\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical = tweets[tweets[\"clean_translation\"].str.contains(\"medical\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "polio = tweets[tweets[\"clean_translation\"].str.contains(\"polio\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare = pd.concat([health, doctor, hospital, insurance, corona, medical, polio])\n",
    "healthcare[\"category\"] = \"healthcare\"\n",
    "tweets = tweets.drop(healthcare.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = tweets[tweets[\"clean_translation\"].str.contains(\"right\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee = tweets[tweets[\"clean_translation\"].str.contains(\"refug\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "women = tweets[tweets[\"clean_translation\"].str.contains(\"women\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = tweets[tweets[\"clean_translation\"].str.contains(\"child\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "displaced = tweets[tweets[\"clean_translation\"].str.contains(\"displac\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_rights = pd.concat([rights, refugee, women, child, displaced])\n",
    "human_rights[\"category\"] = \"human rights\"\n",
    "tweets = tweets.drop(human_rights.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = tweets[tweets[\"clean_translation\"].str.contains(\"bank\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = tweets[tweets[\"clean_translation\"].str.contains(\"account\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking = pd.concat([bank, account])\n",
    "banking[\"category\"] = \"banking\"\n",
    "tweets = tweets.drop(banking.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "deputy = tweets[tweets[\"clean_translation\"].str.contains(\"deputy commissioner\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = tweets[tweets[\"clean_translation\"].str.contains(\"district gvt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = tweets[tweets[\"clean_translation\"].str.contains(\"district gov\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = tweets[tweets[\"clean_translation\"].str.contains(\"district admin\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = tweets[tweets[\"clean_translation\"].str.contains(\"local gvt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = tweets[tweets[\"clean_translation\"].str.contains(\"local gov\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = tweets[tweets[\"clean_translation\"].str.contains(\"local admin\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_gov = pd.concat([deputy, district, dg, da, local, lg, la])\n",
    "district_gov[\"category\"] = \"district government\"\n",
    "tweets = tweets.drop(district_gov.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = tweets[tweets[\"clean_translation\"].str.contains(\"kp gov\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = tweets[tweets[\"clean_translation\"].str.contains(\"kp gvt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "chief = tweets[tweets[\"clean_translation\"].str.contains(\"chief minister\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = tweets[tweets[\"clean_translation\"].str.contains(\"provincial gov\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = tweets[tweets[\"clean_translation\"].str.contains(\"provincial gvt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak = tweets[tweets[\"clean_translation\"].str.contains(\"pakhtunkhwa gov\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "pakg = tweets[tweets[\"clean_translation\"].str.contains(\"pakhtunkhwa gvt\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincial_gov = pd.concat([kp, kg, chief, pg, pt, pak, pakg])\n",
    "provincial_gov[\"category\"] = \"provincial government\"\n",
    "tweets = tweets.drop(provincial_gov.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "imran = tweets[tweets[\"clean_translation\"].str.contains(\"imran\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "khan = tweets[tweets[\"clean_translation\"].str.contains(\"khan\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "federal = tweets[tweets[\"clean_translation\"].str.contains(\"federal\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "nation = tweets[tweets[\"clean_translation\"].str.contains(\"nation\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "pti = tweets[tweets[\"clean_translation\"].str.contains(\"pti\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime = tweets[tweets[\"clean_translation\"].str.contains(\"prime minister\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = tweets[tweets[\"clean_translation\"].str.contains(\"pm\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "federal_gov = pd.concat([imran, khan, federal, nation, pti, prime, pm])\n",
    "federal_gov[\"category\"] = \"federal government\"\n",
    "tweets = tweets.drop(federal_gov.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = tweets[tweets[\"clean_translation\"].str.contains(\"econ\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = tweets[tweets[\"clean_translation\"].str.contains(\"business\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourism = tweets[tweets[\"clean_translation\"].str.contains(\"touri\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = pd.concat([economy, business, tourism])\n",
    "economy[\"category\"] = \"economy\"\n",
    "tweets = tweets.drop(economy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = tweets[tweets[\"clean_translation\"].str.contains(\"water\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "land = tweets[tweets[\"clean_translation\"].str.contains(\"land\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = tweets[tweets[\"clean_translation\"].str.contains(\"power\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = tweets[tweets[\"clean_translation\"].str.contains(\"food\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = pd.concat([water, land, power, food])\n",
    "resources[\"category\"] = \"resources\"\n",
    "tweets = tweets.drop(resources.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all categorized tweets\n",
    "cat_tweets = pd.concat([jobs, education, security, development, environment, transportation, citizens_portal, merger, technology, healthcare, human_rights, banking, district_gov, provincial_gov, federal_gov, economy, resources])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index in original and categorized dataframes\n",
    "tweets = tweets.reset_index()\n",
    "cat_tweets = cat_tweets.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine uncategorized tweets by removing categorized tweets from main dataframe and set category as \"None\"\n",
    "uncat = tweets[~tweets.index.isin(cat_tweets.index)]\n",
    "uncat[\"category\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the dataframes and save\n",
    "tweets = pd.concat([cat_tweets, uncat])\n",
    "\n",
    "with open(\"kp_municipal_tweets_categorized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
