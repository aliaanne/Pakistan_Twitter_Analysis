{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langdetect import detect\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_pk_tweets_all.pickle', \"rb\") as f:\n",
    "    tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"geolocated_users.pickle\", \"rb\") as f:\n",
    "    geo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean text of self-defined user locations\n",
    "tweets[\"user_location\"] = tweets[\"user_location\"].str.lower()\n",
    "tweets[\"user_location\"] = tweets[\"user_location\"].str.replace('[{}]'.format(string.punctuation), '')\n",
    "tweets[\"user_location\"] = tweets[\"user_location\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify users who indicate they are in pakistan\n",
    "tweets[\"country\"] = tweets[\"user_location\"].str.find(\"pakistan\")\n",
    "conditions = [\n",
    "    (tweets['country'] >= 0),\n",
    "    (tweets[\"country\"] < 0)]\n",
    "choices = [\"pakistan\", \"None\"]\n",
    "\n",
    "tweets[\"country\"] = np.select(conditions, choices, default='null')\n",
    "tweets[\"user_location\"] = tweets[\"user_location\"].str.replace(\"pakistan\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge geocoordinated user locations with main dataframe\n",
    "location = tweets[[\"user_id\", \"user_location\", \"country\"]]\n",
    "location = location.groupby([\"user_id\"]).head(1)\n",
    "geo = geo[[\"NAME_3\", \"index_right\"]]\n",
    "merged = location.merge(geo, how='left', left_on=\"user_id\", right_on=\"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select users with self-reported locations, clean the text, and substitute geolocated locations where available\n",
    "users_nan = merged[merged['NAME_3'].isnull()]\n",
    "users_notnan = merged[merged.NAME_3.notnull()]\n",
    "users_notnan[\"NAME_3\"] = users_notnan[\"NAME_3\"].str.lower()\n",
    "users_notnan[\"NAME_3\"] = users_notnan[\"NAME_3\"].str.replace('[{}]'.format(string.punctuation), '')\n",
    "users_notnan[\"NAME_3\"] = users_notnan[\"NAME_3\"].str.strip()\n",
    "users_notnan[\"user_location\"] = users_notnan[\"NAME_3\"]\n",
    "new_users = pd.concat([users_nan, users_notnan], ignore_index = True)\n",
    "new_users = new_users.drop(columns=[\"NAME_3\", \"index_right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Pakistan as location for users located in pakistan without more detailed location info\n",
    "pakistan_locations = location_check[location_check[\"country\"] == \"pakistan\"]\n",
    "pakistan_locations[\"user_location\"] = \"pakistan\"\n",
    "pakistan_locations = pakistan_locations.drop(columns = [\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine users with country only data and city level data and determine if city-level data is in english\n",
    "semi_final_users = pd.concat([location_fine, pakistan_locations], ignore_index = True)\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "semi_final_users['english'] = semi_final_users['user_location'].apply(isEnglish)\n",
    "english_users = semi_final_users[semi_final_users[\"english\"] == True]\n",
    "non_english_users = semi_final_users[semi_final_users[\"english\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ù¾Ø§Ú©Ø³ØªØ§Ù†                          3361\n",
       "Ù„Ø§ÛÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù†                    2749\n",
       "Ù¾Ù†Ø¬Ø§Ø¨ Ù¾Ø§Ú©Ø³ØªØ§Ù†                    2335\n",
       "Ú©Ø±Ø§Ú†ÛŒ Ù¾Ø§Ú©Ø³ØªØ§Ù†                    1883\n",
       "Ø§Ø³Ù„Ø§Ù… Ø¢Ø¨Ø§Ø¯ Ù¾Ø§Ú©Ø³ØªØ§Ù†               1542\n",
       "Ù¾Ø´Ø§ÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù†                      26\n",
       "Ø±Ø§ÙˆÙ„Ù¾Ù†ÚˆÛŒ Ù¾Ø§Ú©Ø³ØªØ§Ù†                   18\n",
       "Ú¯ÙˆØ¬Ø±Ø§Ù†ÙˆØ§Ù„Û Ù¾Ø§Ú©Ø³ØªØ§Ù†                 15\n",
       "Ù…Ù„ØªØ§Ù† Ù¾Ø§Ú©Ø³ØªØ§Ù†                      13\n",
       "Ø³ÛŒØ§Ù„Ú©ÙˆÙ¹ Ù¾Ø§Ú©Ø³ØªØ§Ù†                    10\n",
       "Ø­ÛŒØ¯Ø± Ø¢Ø¨Ø§Ø¯ Ù¾Ø§Ú©Ø³ØªØ§Ù†                  10\n",
       "Ø¯Ø¨ÙŠ Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©       10\n",
       "ðŸ‡µðŸ‡°                                 10\n",
       "Ø³Ù†Ø¯Ú¾ Ù¾Ø§Ú©Ø³ØªØ§Ù†                        8\n",
       "Ø³Ø±Ú¯ÙˆØ¯Ú¾Ø§ Ù¾Ø§Ú©Ø³ØªØ§Ù†                     6\n",
       "Ø§ÛŒØ¨Ù¹ Ø¢Ø¨Ø§Ø¯ Ù¾Ø§Ú©Ø³ØªØ§Ù†                   5\n",
       "Ú©ÙˆØ¦Ù¹Û Ù¾Ø§Ú©Ø³ØªØ§Ù†                       5\n",
       "iÌ‡stanbul tÃ¼rkiye                   5\n",
       "Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©            5\n",
       "karachi  ðŸ‡µðŸ‡°                         3\n",
       "Ø´Ø§Ù„                                 2\n",
       "lahore ðŸ‡µðŸ‡°                           2\n",
       "Ø¨ÛØ§ÙˆÙ„Ù¾ÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù†                    2\n",
       "à¤­à¤¾à¤°à¤¤                                2\n",
       "ð•·ð–†ð–ð–”ð–—ð–Š                              1\n",
       "Ù…Û’ Ø®Ø§Ù†Û’ Ù…ÛŒÚº                         1\n",
       "espaÃ±a                              1\n",
       "Ù…Ø¸ÙØ±Ú¯Ú‘Ú¾ØŒÙ¾Ù†Ø¬Ø§Ø¨ØŒÙ¾Ø§Ú©Ø³ØªØ§Ù†               1\n",
       "ðŸ™‹ðŸ’–ðŸ™‹ðŸŽˆðŸ™‹ðŸ’–ðŸ™‹                             1\n",
       "vormir âš                             1\n",
       "                                 ... \n",
       "â¤â¤                                  1\n",
       "Ø¨ÛØ§ÙˆÙ„Ù¾ÙˆØ± Ù„Ø§ÛÙˆØ±ØŒ Ù¾Ø§Ú©Ø³ØªØ§Ù†             1\n",
       "gujranwalaðŸ‡µðŸ‡°                        1\n",
       "Ù¾Ø´ÛŒÙ†                                1\n",
       "Ù…Û’ Ú©Ø¯Û                              1\n",
       "Ø¯Ø±ÙˆÛŒØ´Ø§Úº Ø¯Û’ ÚˆÛŒØ±Û’ ØªÛ’                  1\n",
       "Ø¬Ø¯Ø© Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©        1\n",
       "Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø© Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§       1\n",
       "city of lightsðŸ‘‰                     1\n",
       "Ø£Ø¨ÙˆØ¸Ø¨ÙŠ Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­       1\n",
       "tÃ¼rkiye                             1\n",
       "iðŸ‡µðŸ‡°ðŸ‡¸ðŸ‡¦                               1\n",
       "Ù„Ø§Ú‘Ú©Ø§Ù†Û Ù¾Ø§Ú©Ø³ØªØ§Ù†                     1\n",
       "ðŸšï¸ðŸšï¸ðŸšï¸                              1\n",
       "Ø³Ø§ÛÛŒÙˆØ§Ù„ Ù¾Ø§Ú©Ø³ØªØ§Ù†                     1\n",
       "Ø¬ÛØ§Ù†ÛŒØ§Úº Ù¾Ù†Ø¬Ø§Ø¨ Ù¾Ø§Ú©Ø³ØªØ§Ù†               1\n",
       "Ø¨Ù†ÙˆÚº Ú¯Ù„ Ø®ÛŒØ¨Ø± Ù¾Ø®ØªÙˆÙ†Ø®ÙˆØ§Û              1\n",
       "Ù¾Ø§Ú©Ø³ØªØ§Ù† faisalabad                  1\n",
       "Ø¨Ù„ÙˆÚ†Ø³ØªØ§Ù†                            1\n",
       "Ù…Ù‚Ø¨ÙˆØ¶Û Ù¾Ø§Ú©Ø³ØªØ§Ù†                      1\n",
       "namjoonâ€™s heart                     1\n",
       "Ø¬Ú¾Ù†Ú¯ ØµØ¯Ø± Ù¾Ø§Ú©Ø³ØªØ§Ù†                    1\n",
       "Ù…ÛŒØ§Ù†ÙˆØ§Ù„ÛŒ Ù¾Ø§Ú©Ø³ØªØ§Ù†                    1\n",
       "Ù…Ù†ÚˆÛŒ Ø¨ÙˆØ±ÛŒÙˆØ§Ù„Û Ù¾Ø§Ú©Ø³ØªØ§Ù†               1\n",
       "multanpk job europ cyprusðŸ‡¨ðŸ‡¾         1\n",
       "Ø¯Ù†ÛŒØ§ Ú©Û’ Ø±Ø´ Ù…ÛŒÚº                      1\n",
       "apka dil main â¤                     1\n",
       "traffic ðŸš—ðŸš—ðŸš¦ðŸš¦                        1\n",
       "in your heart â¤                     1\n",
       "Ø³Ù„Ø·Ù†ØªÙ Ø¹Ø«Ù…Ø§Ù†ÛŒÛ                      1\n",
       "Name: user_location, Length: 144, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Translated non-english location names\n",
    "non_english_users[\"user_location\"].value_counts()\n",
    "pakistan_users = non_english_users[non_english_users[\"user_location\"] == \"Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "pakistan_users[\"user_location\"] = \"pakistan\"\n",
    "lahore_users = non_english_users[non_english_users[\"user_location\"] == \"Ù„Ø§ÛÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "lahore_users[\"user_location\"] = \"lahore\"\n",
    "punjab_users = non_english_users[non_english_users[\"user_location\"] == \"Ù¾Ù†Ø¬Ø§Ø¨ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "punjab_users[\"user_location\"] = \"punjab\"\n",
    "karachi_users = non_english_users[non_english_users[\"user_location\"] == \"Ú©Ø±Ø§Ú†ÛŒ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "karachi_users[\"user_location\"] = \"karachi\"\n",
    "islamabad_users = non_english_users[non_english_users[\"user_location\"] == \"Ø§Ø³Ù„Ø§Ù… Ø¢Ø¨Ø§Ø¯ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "islamabad_users[\"user_location\"] = \"islamabad\"\n",
    "peshawar_users = non_english_users[non_english_users[\"user_location\"] == \"Ù¾Ø´Ø§ÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "peshawar_users[\"user_location\"] = \"peshawar\"\n",
    "rawalpindi_users = non_english_users[non_english_users[\"user_location\"] == \"Ø±Ø§ÙˆÙ„Ù¾Ù†ÚˆÛŒ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "rawalpindi_users[\"user_location\"] = \"rawalpindi\"\n",
    "gujranwala_users = non_english_users[non_english_users[\"user_location\"] == \"Ú¯ÙˆØ¬Ø±Ø§Ù†ÙˆØ§Ù„Û Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "gujranwala_users[\"user_location\"] = \"gujranwala\"\n",
    "multan_users = non_english_users[non_english_users[\"user_location\"] == \"Ù…Ù„ØªØ§Ù† Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "multan_users[\"user_location\"] = \"multan\"\n",
    "hyderabad_users = non_english_users[non_english_users[\"user_location\"] == \"Ø­ÛŒØ¯Ø± Ø¢Ø¨Ø§Ø¯ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "hyderabad_users[\"user_location\"] = \"hyderabad\"\n",
    "sindh_users = non_english_users[non_english_users[\"user_location\"] == \"Ø³Ù†Ø¯Ú¾ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "sindh_users[\"user_location\"] = \"sindh\"\n",
    "sargodha_users = non_english_users[non_english_users[\"user_location\"] == \"Ø³Ø±Ú¯ÙˆØ¯Ú¾Ø§ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "sargodha_users[\"user_location\"] = \"sargodha\"\n",
    "abbottabad_users = non_english_users[non_english_users[\"user_location\"] == \"Ø§ÛŒØ¨Ù¹ Ø¢Ø¨Ø§Ø¯ Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "abbottabad_users[\"user_location\"] = \"abbottabad\"\n",
    "quetta_users = non_english_users[non_english_users[\"user_location\"] == \"Ú©ÙˆØ¦Ù¹Û Ù¾Ø§Ú©Ø³ØªØ§Ù†\"]\n",
    "quetta_users[\"user_location\"] = \"quetta\"\n",
    "karachi2_users = non_english_users[non_english_users[\"user_location\"] == \"karachi  ðŸ‡µðŸ‡°\"]\n",
    "karachi2_users[\"user_location\"] = \"karachi\"\n",
    "lahore2_users = non_english_users[non_english_users[\"user_location\"] == \"lahore ðŸ‡µðŸ‡°\"]\n",
    "lahore2_users[\"user_location\"] = \"lahore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all user-location translated users and english language users and clean up final dataframe\n",
    "translated_users = pd.concat([pakistan_users, lahore_users, karachi_users, punjab_users, islamabad_users, peshawar_users, rawalpindi_users, gujranwala_users, multan_users, hyderabad_users, sindh_users, sargodha_users, abbottabad_users, quetta_users, karachi2_users, lahore2_users], ignore_index = True)\n",
    "final_users = pd.concat([english_users, translated_users], ignore_index =True)\n",
    "final_users = final_users.drop(columns = [\"english\"])\n",
    "tweets = tweets.drop(columns = [\"tweet_id\", \"user_location\", \"tweet_longitude\", \"tweet_latitude\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge user location data back with tweet data and save\n",
    "cleaned_users_locations = tweets.merge(final_users, how='left', left_on=\"user_id\", right_on=\"user_id\")\n",
    "with open(\"all_tweets_location_cleaned.pickle\", \"wb\") as f:\n",
    "    pickle.dump(cleaned_users_locations, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
