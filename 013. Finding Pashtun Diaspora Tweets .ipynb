{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dval/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import re \n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open non-kp tweets\n",
    "with open('non_kp_tweets.pickle', \"rb\") as f:\n",
    "    tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify tweets labeled as pashto and delete from dataset\n",
    "twitter_pashto = tweets[tweets[\"tweet_lang\"]==\"ps\"]\n",
    "tweets = tweets[tweets[\"tweet_lang\"]!=\"ps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload user created-pashto stopwords and search in tweets, deleting them from dataset\n",
    "pashto_stopwords = pd.read_excel(\"new_pashto_stopwords.xlsx\")\n",
    "pashto_stopwords = pashto_stopwords[\"word\"].to_list()\n",
    "\n",
    "def exact_match(stopwords, string):\n",
    "    for word in stopwords:\n",
    "        if re.search(r'\\b' + word + r'\\b', string):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "tweets[\"pashto\"] = tweets.text.apply(lambda x: exact_match(pashto_stopwords, x))\n",
    "pashto_from_stopwords = tweets[tweets[\"pashto\"]==True]\n",
    "tweets = tweets[tweets[\"pashto\"]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat both sets of pashto language tweets and save\n",
    "pashto_tweets = pd.concat([twitter_pashto, pashto_from_stopwords], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify user IDs of people who tweeted in pashto and gather all of their tweets in all languages\n",
    "pashto_users = pashto_tweets[[\"user_id\"]]\n",
    "pashto_users = pashto_users[\"user_id\"].unique()\n",
    "pashto_users = pd.DataFrame(pashto_users)\n",
    "pashto_users.columns = [\"user_id\"]\n",
    "pashto_tweets = tweets.merge(pashto_users, on = \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Pashto diaspora tweets by language and save\n",
    "pashto_tweets = pashto_tweets.dropna()\n",
    "urdu_pashto_tweets = pashto_tweets[pashto_tweets[\"tweet_lang\"]==\"ur\"]\n",
    "english_pashto_tweets = pashto_tweets[pashto_tweets[\"tweet_lang\"]==\"en\"]\n",
    "\n",
    "with open(\"non_kp_tweets_pashto.pickle\", \"wb\") as f:\n",
    "    pickle.dump(pashto_tweets, f)\n",
    "    \n",
    "with open(\"non_kp_tweets_non_pashto.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tweets, f)\n",
    "    \n",
    "with open(\"non_kp_tweets_urdu_pashto.pickle\", \"wb\") as f:\n",
    "    pickle.dump(urdu_pashto_tweets, f)\n",
    "    \n",
    "with open(\"non_kp_tweets_english_pashto.pickle\", \"wb\") as f:\n",
    "    pickle.dump(english_pashto_tweets, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
